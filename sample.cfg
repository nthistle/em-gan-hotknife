; Sample config file for a training run
[global]
pretrain=true
train=true
run_output=/path/to/output/directory
valid_container=/path/to/container.n5
valid_dataset=path/to/dataset

; Only needed if train=true
gap_container=/path/to/container.n5
gap_dataset=path/to/dataset
gap_location=250
; z-slice index relative to dataset


; Only necessary if global.train=true
[train]
num_epochs=100
num_minibatch=64
minibatch_size=2
instance_noise=false

; Instance Noise doesn't really help, this is always set to false
; Only necessary if instance_noise=true
instance_noise_std_dev=0
anneal_noise=30

; Only needed if pretrain=false
pretrained_model=/path/to/model.h5
generator_learning_rate=1e-4

generator_optimizer=adam
; Currently not used, generator optimizer is always Adam

generator_mask_size=10
; Total thickness of mask size, diameter not radius

penalty_learning_rate=1e-4
; For applying the "penalty" for deviating outside of mask area

discriminator_learning_rate=1e-5

discriminator_optimizer=adam
; Currently not used, discriminator optimizer is always Adam

discriminator_architecture=default
; See bottom of models.py for valid options (Currently "a", "b", "c", "default")

; Anything in this format gets passed to the constructor for that architecture
discriminator_arg_[argname]=[value]
; No Square Brackets

;e.g. discriminator_arg_init_filters=19
;discriminator_arg_batch_norm=false


; Only necessary if global.pretrain=true
[pretrain]
num_epochs=100
num_minibatch=64
minibatch_size=2

generator_architecture=default
; See bottom of models.py for valid options (Currently "a", "b", "default")

generator_learning_rate=1e-4

; Anything in this format gets passed to the constructor for that architecture
generator_arg_[argname]=[value]
;e.g. generator_arg_regularization=0.0
;generator_arg_batch_norm=true
